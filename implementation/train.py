import pickle
import nltk
import sys
import string

# list of honourifics to check against
honourific_list = [
	"mr.",
	"mrs.",
	"dr.",
	"ms.",
	"prof.",
	"pvt.",
	"cpl.",
	"mcpl.",
	"sgt.",
	"wo.",
	"cdt.",
	"lt.",
	"cpt.",
	"mjr.",
	"col.",
	"gen.",
	"hrm."
]

# feature function for honourifics
def isHonourific(context, response):
	# grab the relevant token
	candidate = context[3].lower()

	# check it against the list
	for honourific in honourific_list:	
		if candidate == honourific:
			return 1

	# fall-through
	return 0

def setupData(filename):
	f = open(filename, 'r')

	lines = f.readlines()
	
	contexts = []

	for line in lines:
		words = (string.split(line))
	#	for word in words:
	#		print word + " ",
	#	print
		contexts.append(words)

	contextFeatures = []	
	for context in contexts:
		case = []
		features = dict(
			honourificTest= isHonourific(context, True))
		if context[7] == "<Y>":
			classification = "y"
		else:
			classification = "x"
		case.append(features)
		case.append(classification)
		contextFeatures.append(case)

	return contextFeatures

def train_maxent(algorithm, trainingData):
	try:
		classifier = nltk.MaxentClassifier.train(trainingData, 'GIS', trace=0, max_iter=1000)
	except Exception, e:
		classifier = e	
	return classifier

if len(sys.argv) == 3:
	trainingData = setupData(sys.argv[1])
	model = train_maxent(nltk.classify.MaxentClassifier.ALGORITHMS[0], trainingData)
	outputModel = open(sys.argv[2], 'w')
	pickle.dump(model, outputModel)

else:
	print "Usage: python train.py <trainFile> <nameOfModel>"
	print "    Where <trainFile> is the path to a context file generated by",
	print "Contextualizer."
	print "    and <nameOfModel> is the path to save the generated model to."
